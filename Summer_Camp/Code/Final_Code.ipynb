{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"39784746e3dc47b09ec52bc9c41c4947":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e227fe7cd2354eb980c3bccffb94ca0b","IPY_MODEL_f89d0c37266b4b5cbb16e9425f5581d0","IPY_MODEL_af547b184a6f4d34a9447f3eeae5809c"],"layout":"IPY_MODEL_c87556cd3640462a88161ecd00a0d9cb"}},"e227fe7cd2354eb980c3bccffb94ca0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2284076bbd4b419ea7afacf690d2dddb","placeholder":"​","style":"IPY_MODEL_9ecf77fdc0c94cad9d6ccf7b2c245ac9","value":"model.safetensors: 100%"}},"f89d0c37266b4b5cbb16e9425f5581d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7126d1229cd48739fcd2b58c704d9ed","max":46807446,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ad427ebbc45468ba34c06092b1272b8","value":46807446}},"af547b184a6f4d34a9447f3eeae5809c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf32f705e0424d4dacced6ded1233b0c","placeholder":"​","style":"IPY_MODEL_0d5d772b6ca34b73b192746b756d5bba","value":" 46.8M/46.8M [00:00&lt;00:00, 61.5MB/s]"}},"c87556cd3640462a88161ecd00a0d9cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2284076bbd4b419ea7afacf690d2dddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ecf77fdc0c94cad9d6ccf7b2c245ac9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7126d1229cd48739fcd2b58c704d9ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ad427ebbc45468ba34c06092b1272b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf32f705e0424d4dacced6ded1233b0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d5d772b6ca34b73b192746b756d5bba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["### Group Name: Big Bang Theory\n","\n","Team members:\n","\n","1. Arman Feili: 2101835\n","2. Sohrab Seyyedi Parsa: 2101087\n","3. Milad Torabi: 2103454\n","4. Sharifeh Alaei: 2050840"],"metadata":{"id":"V6AiGDiea8aS"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"TTUn2Oczb0f4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727787215795,"user_tz":-120,"elapsed":26434,"user":{"displayName":"arman feili","userId":"17968569339475105674"}},"outputId":"9db87d09-4237-4b3c-e02e-b73000718cfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","# Mount drive from Google\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","source":["\n","!pip install timm"],"metadata":{"id":"XG-hXnYA2Tke","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727787305250,"user_tz":-120,"elapsed":4446,"user":{"displayName":"arman feili","userId":"17968569339475105674"}},"outputId":"e07d88e6-665e-4a03-9296-b3b2728a0072"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: timm\n","Successfully installed timm-1.0.9\n"]}]},{"cell_type":"code","source":["1# my_lib/__init__.py\n","import os\n","import PIL.Image\n","import timm\n","import torch.nn as nn\n","import torch\n","import torchvision.transforms as T\n","import torch\n","import numpy as np\n","import random\n","import json\n","import pandas as pd\n","import numpy as np\n","import argparse\n","\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import Dataset\n","from datetime import datetime\n","from dataclasses import dataclass\n","from sklearn.model_selection import KFold\n","from typing import Tuple\n","\n","root_path = '/content/gdrive/MyDrive/Big-Bang-Theory/Code'\n","\n","csv_train_file = root_path + \"/../dataset/train.csv\"\n","csv_test_file = root_path + \"/../dataset/test.csv\"\n","\n","root_train_images = root_path + \"/../dataset/images/train\"\n","root_test_images = root_path + \"/../dataset/images/test\"\n","\n","csv_split_file: str = root_path + \"/../dataset/fold.csv\"\n","\n","outputs = root_path + \"/../outputs\"\n","\n","@dataclass\n","class VisualConfig:\n","    def to_json(self, path: str):\n","        with open(path, \"w\") as fp:\n","            json.dump(self.__dict__, fp, indent=2)\n","\n","    @classmethod\n","    def from_json(self, path: str):\n","        with open(path, \"r\") as fp:\n","            json_obj = json.load(fp)\n","        return VisualConfig(**json_obj)\n","\n","    project_name: str = \"project\"\n","    random_state: int = 42\n","    device: str = \"cuda\"\n","    seed: int = 42\n","    num_classes: int = 4\n","    model_name: str = \"resnet18\"\n","    pretrained: bool = True\n","    train_input_size: Tuple[int, int] = (224, 224)\n","    test_input_size: Tuple[int, int] = (224, 224)\n","    aug_color_jitter_b: float = 0.1\n","    aug_color_jitter_c: float = 0.1\n","    aug_color_jitter_s: float = 0.1\n","    norm_mean: Tuple[float, float, float] = (0.485, 0.456, 0.406)\n","    norm_std: Tuple[float, float, float] = (0.229, 0.224, 0.225)\n","    fold: int = 0\n","\n","    root_path = '/content/gdrive/MyDrive/Big-Bang-Theory/Code'\n","\n","    csv_train_file = root_path + \"/../dataset/train.csv\"\n","    csv_test_file = root_path + \"/../dataset/test.csv\"\n","\n","    root_train_images = root_path + \"/../dataset/images/train\"\n","    root_test_images = root_path + \"/../dataset/images/test\"\n","\n","    csv_split_file: str = root_path + \"/../dataset/fold.csv\"\n","\n","    outputs = root_path + \"/../outputs\"\n","\n","    num_epochs: int = 15\n","    batch_size: int = 32\n","    test_batch_size: int = 32\n","    num_workers: int = 0\n","    lr: float = 1.0e-3\n","    weight_decay: float = 1e-4\n","\n","class DFDataset(Dataset):\n","    def __init__(self, root, df, transform=None):\n","        super().__init__()\n","        self.images = [os.path.join(root, str(row[1][\"image_name\"])) for row in df.iterrows()]\n","        self.target = df[\"target\"].values if \"target\" in df.columns else None\n","        self.transform = transform\n","        self.image_cache = {}  # Dictionary to store cached images\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        if idx in self.image_cache:\n","            img = self.image_cache[idx]\n","        else:\n","            try:\n","                img = PIL.Image.open(self.images[idx])\n","                self.image_cache[idx] = img  # Cache the image\n","            except (PIL.UnidentifiedImageError, IOError) as e:\n","                print(f\"Error loading image {self.images[idx]}: {e}\")\n","                return None  # or handle appropriately depending on your requirement\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img if self.target is None else (img, self.target[idx])\n","\n","class VisualModelTimm(nn.Module):\n","    def __init__(self, model_name, num_classes, pretrained=True):\n","        super().__init__()\n","        self.encoder = timm.create_model(model_name, num_classes=0, pretrained=pretrained)\n","        config = timm.get_pretrained_cfg(model_name=model_name, allow_unregistered=True).to_dict()\n","        with torch.no_grad():\n","            emb = self.encoder(torch.rand(1, *config[\"input_size\"]))\n","            self.embedding_size = emb.shape[1]\n","        self.head = nn.Linear(self.embedding_size, num_classes)\n","\n","    def encode(self, x):\n","        return self.encoder(x)\n","\n","    def forward(self, x):\n","        return self.head(self.encode(x))\n","\n","class RunningMean:\n","    def __init__(self, name: str = \"\"):\n","        self.name = name\n","        self.restart()\n","\n","    def restart(self):\n","        self.mean = 0\n","        self.n = 0\n","\n","    def update(self, value):\n","        self.mean = self.mean + (value - self.mean) / (self.n + 1)\n","        self.n += 1\n","\n","    def __str__(self):\n","        return f\"{self.mean}\"\n","\n","def get_preprocessing(config: VisualConfig, is_training=True):\n","    transform = [T.RandomRotation(15),\n","                 T.RandomResizedCrop(size=(128, 128), scale=(0.8, 1)),  # Resized smaller\n","                 T.ColorJitter(config.aug_color_jitter_b, config.aug_color_jitter_c, config.aug_color_jitter_s, 0.0),\n","                 T.RandomHorizontalFlip()] if is_training else [T.Resize((128, 128))]  # Test resize smaller\n","    transform += [T.ToTensor(), T.Normalize(config.norm_mean, config.norm_std)]\n","    return T.Compose(transform)\n","\n","def seed_everything(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    np.random.seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    random.seed(seed)\n","\n","def get_output_folder(project_name):\n","    return project_name + \"_\" + datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\")\n","\n","\n","def train_epoch(epoch, model, loader, criterion) -> dict:\n","    model.train()\n","    mean_loss = RunningMean()\n","    correct = 0\n","    total = 0\n","\n","    print(f\"Epoch {epoch} started...\")\n","\n","    for batch_idx, (image_batch, label_batch) in enumerate(loader):\n","        image_batch, label_batch = image_batch.to(cfg.device), label_batch.to(cfg.device)\n","\n","        # Forward pass\n","        logits = model(image_batch)\n","        loss = criterion(logits, label_batch)\n","\n","        # Backward pass and optimization\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","        lr_sched.step()\n","\n","        # Update running mean of the loss\n","        mean_loss.update(loss.item())\n","\n","        # Calculate accuracy\n","        _, predicted = torch.max(logits, 1)\n","        total += label_batch.size(0)\n","        correct += (predicted == label_batch).sum().item()\n","\n","        # Print the loss for the current batch\n","        print(f\"Epoch {epoch}, Batch {batch_idx + 1}/{len(loader)}: Loss = {loss.item():.4f}\")\n","\n","    accuracy = 100 * correct / total\n","\n","    print(f\"Epoch {epoch} completed. Mean Loss = {mean_loss.mean:.4f}\")\n","\n","    # Return both mean loss and accuracy\n","    return {\"mean_loss\": mean_loss.mean, \"accuracy\": accuracy}\n","\n","# Evaluation Loop\n","def eval_epoch(epoch, model, loader, criterion) -> dict:\n","    model.eval()\n","    y_pred_list, prob_pred_list, y_true_list = [], [], []\n","    mean_loss = RunningMean()\n","    for image_batch, label_batch in loader:\n","        image_batch, label_batch = image_batch.to(cfg.device), label_batch.to(cfg.device)\n","        with torch.no_grad():\n","            logits = model(image_batch)\n","        y_pred_list += list(torch.argmax(logits, dim=1).cpu().numpy())\n","        prob_pred_list += [torch.softmax(logits, dim=1).cpu().numpy()]\n","        y_true_list += list(label_batch.cpu().numpy())\n","        mean_loss.update(criterion(logits, label_batch).item())\n","    return {\"acc\": accuracy_score(y_true_list, y_pred_list), \"probabilities\": np.vstack(prob_pred_list), \"mean_loss\": mean_loss}\n","\n","# Test Loop\n","def test_epoch(epoch, model, loader, df_test) -> dict:\n","    model.eval()\n","    y_pred_list, prob_pred_list = [], []\n","    target_list = [] if hasattr(loader.dataset, 'target') and loader.dataset.target is not None else None\n","\n","    for batch in loader:\n","        if target_list is not None:\n","            image_batch, label_batch = batch\n","            target_list += list(label_batch.cpu().numpy())  # Collect the targets\n","        else:\n","            image_batch = batch  # Only images in the test set\n","\n","        image_batch = image_batch.to(cfg.device)\n","        with torch.no_grad():\n","            logits = model(image_batch)\n","\n","        y_pred_list += list(torch.argmax(logits, dim=1).cpu().numpy())\n","        prob_pred_list += [torch.softmax(logits, dim=1).cpu().numpy()]\n","\n","    results = {\"probabilities\": np.vstack(prob_pred_list), \"prediction\": y_pred_list}\n","    if target_list is not None:\n","        results[\"target\"] = target_list\n","\n","    return results\n","\n","def save_checkpoint(model, optimizer, epoch, output_folder, eval_score):\n","    print(f\"Output folder: {output_folder}\")  # Debugging output folder path\n","\n","    \"\"\"Save model, optimizer state, and current epoch.\"\"\"\n","    checkpoint_path = os.path.join(output_folder, f\"model_checkpoint_{epoch}_{eval_score:.4f}.pth\")\n","    print(f\"Saving checkpoint at {checkpoint_path}\")  # Add this line for debugging\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, checkpoint_path)\n","    print(f\"Checkpoint saved at {checkpoint_path}\")\n","\n","def load_checkpoint(model, optimizer, output_folder):\n","    \"\"\"Load model and optimizer state from a checkpoint if available.\"\"\"\n","    # Print the output folder to verify path\n","    print(f\"Loading from checkpoint folder: {output_folder}\")\n","\n","    # List files in the output folder\n","    checkpoint_files = [f for f in os.listdir(output_folder) if f.startswith(\"model_checkpoint\")]\n","    print(f\"Checkpoint files found: {checkpoint_files}\")\n","\n","    if not checkpoint_files:\n","        print(\"No checkpoint found, starting training from scratch.\")\n","        return model, optimizer, 0\n","\n","    # Find the latest checkpoint\n","    latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n","    checkpoint_path = os.path.join(output_folder, latest_checkpoint)\n","\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n","    print(f\"Loaded checkpoint from {checkpoint_path}, resuming from epoch {epoch}\")\n","\n","    return model, optimizer, epoch\n","\n"],"metadata":{"id":"yHYFTui_Ad7L","executionInfo":{"status":"ok","timestamp":1727787319127,"user_tz":-120,"elapsed":13881,"user":{"displayName":"arman feili","userId":"17968569339475105674"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","\n","df = pd.read_csv(csv_train_file)\n","kf = KFold(5, shuffle=True, random_state=42)\n","\n","df_fold = pd.DataFrame()\n","df_fold[\"fold\"] = np.zeros(len(df))\n","\n","for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n","    df_fold.loc[val_idx, \"fold\"] = int(fold)\n","\n","df_fold[\"fold\"] = df_fold[\"fold\"].astype(int)\n","df_fold.to_csv(csv_split_file, index=False)\n","\n","# TEST_config.py\n","cfg = VisualConfig(random_state=1000)\n","cfg.to_json(\"example.json\")\n","print(cfg)\n","\n","# TEST_models_visual.py\n","model = VisualModelTimm(model_name=\"resnet50\", num_classes=4, pretrained=False)\n","embedding = model.encode(torch.rand(8, 3, 224, 224))\n","print(model)\n","print(embedding.shape)\n","\n","# TEST_preprocessing_visual.py\n","config = VisualConfig()\n","tr_train = get_preprocessing(config, is_training=True)\n","tr_test = get_preprocessing(config, is_training=False)\n","\n","df_train = pd.read_csv(csv_train_file)\n","train_ds = DFDataset(root_train_images, df_train, transform=tr_train)\n","print(train_ds[5])\n","print(tr_train)\n","print(tr_test)\n","\n","if __name__ == \"__main__\":\n","    import sys\n","    if 'ipykernel' in sys.modules:\n","        args = None  # Bypass argument parsing when running in Jupyter\n","    else:\n","        parser = argparse.ArgumentParser()\n","        parser.add_argument(\"--cfg\", type=str, required=False, default=None)\n","        args = parser.parse_args()\n","\n","    if args is not None and args.cfg is not None:\n","        print(\"Loading config...\")\n","        cfg = VisualConfig.from_json(args.cfg)\n","    else:\n","        cfg = VisualConfig()\n","\n","    seed_everything(cfg.seed)\n","\n","    model = VisualModelTimm(cfg.model_name, cfg.num_classes, pretrained=cfg.pretrained)\n","\n","    train_transform = get_preprocessing(cfg, is_training=True)\n","    val_transform = get_preprocessing(cfg, is_training=False)\n","    test_transform = get_preprocessing(cfg, is_training=False)\n","\n","    df = pd.read_csv(cfg.csv_train_file)\n","    split = pd.read_csv(cfg.csv_split_file)\n","\n","    if cfg.fold == -1:\n","        df_train = df\n","        evaluate = False\n","    else:\n","        df_train = df.loc[split[\"fold\"] != cfg.fold, :]\n","        df_val = df.loc[split[\"fold\"] == cfg.fold, :]\n","        evaluate = True\n","\n","    df_test = pd.read_csv(cfg.csv_test_file)\n","\n","    # Create Data Loaders with optimized batch size and reduced num_workers (from 4 to 2)\n","    train_ds = DFDataset(cfg.root_train_images, df_train, transform=train_transform)\n","    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size // 2, num_workers=0, shuffle=True, drop_last=False)\n","\n","    if evaluate:\n","        val_ds = DFDataset(cfg.root_train_images, df_val, transform=val_transform)\n","        val_loader = DataLoader(val_ds, batch_size=cfg.test_batch_size // 2, num_workers=0, shuffle=False)\n","\n","    test_ds = DFDataset(cfg.root_test_images, df_test, transform=test_transform)\n","    test_loader = DataLoader(test_ds, batch_size=cfg.test_batch_size // 2, num_workers=0, shuffle=False, drop_last=False)\n","\n","    optim = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n","    total_iterations = cfg.num_epochs * len(train_loader)\n","    lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optim, T_max=total_iterations, eta_min=cfg.lr * 0.01)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    output_folder = f\"{outputs}/{get_output_folder(cfg.project_name)}\"\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    # Load model and optimizer from checkpoint if available\n","    model, optim, start_epoch = load_checkpoint(model, optim, output_folder)\n","\n","    model.to(cfg.device)\n","\n","    # Start training from the loaded epoch\n","    for epoch in range(start_epoch, cfg.num_epochs):\n","        train_results = train_epoch(epoch, model, train_loader, criterion)\n","        print(f\"Training Accuracy: {train_results['accuracy']}%\")\n","\n","        if evaluate:\n","            val_results = eval_epoch(epoch, model, val_loader, criterion)\n","            print(f\"Validation Accuracy: {val_results['acc']*100:.2f}%\")\n","            df_val.loc[:, [f\"prob_{i}\" for i in range(cfg.num_classes)]] = val_results[\"probabilities\"]\n","            eval_score = val_results[\"acc\"]\n","            df_val.to_csv(os.path.join(output_folder, f\"fold_{cfg.fold}_valpred_{epoch}_{eval_score:.4f}.csv\"), index=False)\n","        else:\n","            eval_score = -1\n","\n","        # Save the model and optimizer after each epoch\n","        save_checkpoint(model, optim, epoch, output_folder, eval_score)\n","\n","        # Modify test results saving section\n","        test_results = test_epoch(epoch, model, test_loader, df_test)\n","        df_test.loc[:, [f\"prob_{i}\" for i in range(cfg.num_classes)]] = test_results[\"probabilities\"]\n","        df_test[\"prediction\"] = test_results[\"prediction\"]\n","\n","        if \"target\" in test_results:\n","            df_test[\"target\"] = test_results[\"target\"]  # Add the target column if available\n","\n","        # Save to CSV with or without the target column\n","        df_test.to_csv(os.path.join(output_folder, f\"fold_{cfg.fold}_testpred_{epoch}_{eval_score:.4f}.csv\"), index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["39784746e3dc47b09ec52bc9c41c4947","e227fe7cd2354eb980c3bccffb94ca0b","f89d0c37266b4b5cbb16e9425f5581d0","af547b184a6f4d34a9447f3eeae5809c","c87556cd3640462a88161ecd00a0d9cb","2284076bbd4b419ea7afacf690d2dddb","9ecf77fdc0c94cad9d6ccf7b2c245ac9","a7126d1229cd48739fcd2b58c704d9ed","4ad427ebbc45468ba34c06092b1272b8","cf32f705e0424d4dacced6ded1233b0c","0d5d772b6ca34b73b192746b756d5bba"]},"id":"UROZR2GlJbCi","outputId":"95fc3290-81bf-4408-b57c-2ce07702aa9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VisualConfig(project_name='project', random_state=1000, device='cuda', seed=42, num_classes=4, model_name='resnet18', pretrained=True, train_input_size=(224, 224), test_input_size=(224, 224), aug_color_jitter_b=0.1, aug_color_jitter_c=0.1, aug_color_jitter_s=0.1, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), fold=0, csv_split_file='/content/gdrive/MyDrive/Big-Bang-Theory/Code/../dataset/fold.csv', num_epochs=15, batch_size=32, test_batch_size=32, num_workers=0, lr=0.001, weight_decay=0.0001)\n","VisualModelTimm(\n","  (encoder): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act1): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n","    (fc): Identity()\n","  )\n","  (head): Linear(in_features=2048, out_features=4, bias=True)\n",")\n","torch.Size([8, 2048])\n","(tensor([[[ 0.0912,  0.0912,  0.0741,  ..., -0.8849, -0.8849, -0.9020],\n","         [ 0.0912,  0.0912,  0.0741,  ..., -0.8849, -0.8849, -0.9020],\n","         [ 0.0912,  0.0741,  0.0741,  ..., -0.8849, -0.8849, -0.9020],\n","         ...,\n","         [-1.9980, -2.0323, -1.7412,  ..., -1.7925, -1.9809, -1.9467],\n","         [-1.9809, -1.9467, -1.8439,  ..., -2.1179, -2.1179, -2.1179],\n","         [-1.9809, -1.9124, -1.9467,  ..., -2.1179, -2.1179, -2.1179]],\n","\n","        [[ 0.5903,  0.5903,  0.5728,  ..., -0.1450, -0.1450, -0.1275],\n","         [ 0.5903,  0.5903,  0.5728,  ..., -0.1450, -0.1450, -0.1275],\n","         [ 0.5903,  0.5728,  0.5728,  ..., -0.1450, -0.1450, -0.1275],\n","         ...,\n","         [-1.7731, -1.7906, -1.4755,  ..., -1.5630, -1.7556, -1.7381],\n","         [-1.7381, -1.6856, -1.5630,  ..., -2.0357, -2.0357, -2.0357],\n","         [-1.7556, -1.6856, -1.7206,  ..., -2.0357, -2.0357, -2.0357]],\n","\n","        [[ 1.4200,  1.4374,  1.4374,  ...,  0.7925,  0.7925,  0.7925],\n","         [ 1.4200,  1.4200,  1.4200,  ...,  0.7925,  0.7925,  0.7925],\n","         [ 1.4200,  1.3851,  1.3851,  ...,  0.7925,  0.7925,  0.7925],\n","         ...,\n","         [-1.8044, -1.8044, -1.6824,  ..., -1.6650, -1.7173, -1.6650],\n","         [-1.7522, -1.7347, -1.6824,  ..., -1.8044, -1.8044, -1.8044],\n","         [-1.6999, -1.6650, -1.6824,  ..., -1.8044, -1.8044, -1.8044]]]), 1)\n","Compose(\n","    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n","    RandomResizedCrop(size=(128, 128), scale=(0.8, 1), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n","    ColorJitter(brightness=(0.9, 1.1), contrast=(0.9, 1.1), saturation=(0.9, 1.1), hue=None)\n","    RandomHorizontalFlip(p=0.5)\n","    ToTensor()\n","    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",")\n","Compose(\n","    Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=True)\n","    ToTensor()\n","    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39784746e3dc47b09ec52bc9c41c4947"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loading from checkpoint folder: /content/gdrive/MyDrive/Big-Bang-Theory/Code/../outputs/project_10-01-2024-12-56-37\n","Checkpoint files found: []\n","No checkpoint found, starting training from scratch.\n","Epoch 0 started...\n","Epoch 0, Batch 1/200: Loss = 1.4490\n","Epoch 0, Batch 2/200: Loss = 1.3491\n","Epoch 0, Batch 3/200: Loss = 1.3697\n","Epoch 0, Batch 4/200: Loss = 1.4374\n","Epoch 0, Batch 5/200: Loss = 1.4210\n","Epoch 0, Batch 6/200: Loss = 1.3024\n","Epoch 0, Batch 7/200: Loss = 1.3584\n","Epoch 0, Batch 8/200: Loss = 1.3659\n","Epoch 0, Batch 9/200: Loss = 1.5367\n","Epoch 0, Batch 10/200: Loss = 1.2462\n","Epoch 0, Batch 11/200: Loss = 1.3743\n","Epoch 0, Batch 12/200: Loss = 1.3601\n","Epoch 0, Batch 13/200: Loss = 1.3938\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9LqH_fk-Jw2H"},"execution_count":null,"outputs":[]}]}